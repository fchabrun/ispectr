{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "latter-pearl",
   "metadata": {},
   "source": [
    "# Input Data Quality Check\n",
    "\n",
    "Dans ce fichier nous allons vérifier que les données d'entrée sont correctement formatées pour leur utilisation dans DELTA.\n",
    "\n",
    "Il s'agit d'un fichier .csv (format anglo-saxon : \",\" pour séparer les colonnes) qui doit suivre plusieurs spécifications vérifiées dans le script qui suit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-shirt",
   "metadata": {},
   "source": [
    "## 1. Déclaration des variables, chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guilty-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "COLOR_PRINT_RED_START = \"\\x1b[31m\"\n",
    "COLOR_PRINT_RED_END = \"\\x1b[31m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-activity",
   "metadata": {},
   "source": [
    "En premier lieu, on va commencer par indiquer le chemin vers le fichier de données.\n",
    "\n",
    "La variable `EXTENDED_DATASET_MODE` permet de choisir si le dataset que l'on charge est un dataset *extended* (`EXTENDED_DATASET_MODE=True`) ou standard (`EXTENDED_DATASET_MODE=False`).\n",
    "- En mode standard, les données d'annotations sont uniquement les labels textuelles (format original présenté par SEBIA) ;\n",
    "- En mode *extended*, les données d'annotations (y) sont les *maps de segmentation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guilty-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on précise si on souhaite avoir les données en mode \"extended\"\n",
    "EXTENDED_DATASET_MODE = True\n",
    "\n",
    "# si on veut le fichier de données \"classique\"\n",
    "if not EXTENDED_DATASET_MODE:\n",
    "    data_file_path = r\"C:\\Users\\admin\\Documents\\Capillarys\\data\\2021\\ifs\\formatted_data\\angers_dataset_v1.csv\"\n",
    "\n",
    "# si on veut le fichier de données \"extended\" (i.e. : y = maps de segmentation)\n",
    "if EXTENDED_DATASET_MODE:\n",
    "    data_file_path = r\"C:\\Users\\admin\\Documents\\Capillarys\\data\\2021\\ifs\\formatted_data\\angers_dataset_extended_v1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bound-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge le dataset, en mode \"string\" pour récupérer EXACTEMENT les données telles qu'elles sont écrites dans le fichier .csv\n",
    "raw_dataset = pd.read_csv(data_file_path, index_col=False, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-murray",
   "metadata": {},
   "source": [
    "## 2. Vérification des données\n",
    "\n",
    "Dans les parties qui suivent, les différents QC sont réalisés. A chaque fois, l'output de la cellule s'affiche en noir si tous les QC s'exécutent correctement, ou en rouge en cas d'erreur.\n",
    "\n",
    "**Si des items s'affichent en <font color='red'>rouge</font> dans l'output lors de l'exécution d'une cellule, c'est qu'au moins une erreur a été détectée lors du QC !**\n",
    "\n",
    "### 2.1. Quality check basique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-anniversary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 19834 colonnes (nombre d'entrées + 1)\n",
      "Le dataset contient 301 lignes (comme attendu)\n"
     ]
    }
   ],
   "source": [
    "# On affiche le nombre de colonnes : c'est le nombre de courbes contenues dans le tableau + 1 (une colonne pour les indices des points)\n",
    "print(\"Le dataset contient {} colonnes (nombre d'entrées + 1)\".format(raw_dataset.shape[1]))\n",
    "\n",
    "# On vérifie qu'il y a bien 301 lignes : une ligne pour chaque point de la courbe (300) + la ligne des labels\n",
    "# La première *ligne* du tableau .csv contient les noms des colonnes et n'est donc pas comptabilisée ici\n",
    "if raw_dataset.shape[0] != 301:\n",
    "    print(COLOR_PRINT_RED_START + \"Le dataset contient {} lignes ! Attendu : 301 lignes\".format(raw_dataset.shape[0]) + COLOR_PRINT_RED_END)\n",
    "else:\n",
    "    print(\"Le dataset contient {} lignes (comme attendu)\".format(raw_dataset.shape[0]))\n",
    "    \n",
    "if raw_dataset.iloc[0,0] != \"Labels\":\n",
    "    print(COLOR_PRINT_RED_START + \"La première valeur de la première colonne (position [0,0]) doit être == \\\"Labels\\\"\" + COLOR_PRINT_RED_END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-constitutional",
   "metadata": {},
   "source": [
    "### 2.2. Quality check pour les noms de colonnes\n",
    "\n",
    "1. Vérification du nom de la première colonne\n",
    "2. Vérification du nombre de colonnes\n",
    "3. Vérification du nom des colonnes\n",
    "4. Vérification de la cohérence nombre/nom des colonnes & échantillons du tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "victorian-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start columns QC\n",
      "Le jeu de données contient 1803 échantillons\n",
      "Ended columns QC\n"
     ]
    }
   ],
   "source": [
    "print(\"Start columns QC\")\n",
    "\n",
    "# La première colonne doit avoir pour nom : \" \"\n",
    "if raw_dataset.columns[0] != \" \":\n",
    "    print(COLOR_PRINT_RED_START + \"La première colonne devrait avoir un nom vide (== \\\" \\\") mais contient : <{}>\".format(raw_dataset.columns[0]) + COLOR_PRINT_RED_END)\n",
    "\n",
    "# Le nombre de colonnes (-1 pour la première colonne des indices des points des courbes)\n",
    "# doit être un multiple de 11 : ELP, G, A, M, k, l, G-y, A-y, M-y, k-y, l-y pour chaque échantillon\n",
    "if (raw_dataset.shape[1]-1) % 11 != 0:\n",
    "    print(COLOR_PRINT_RED_START + \"Le nombre de colonnes - 1 devrait être un multiple de 11 (ex : 12 colonnes au total dans le tableau)\" + COLOR_PRINT_RED_END)\n",
    "else:\n",
    "    print(\"Le jeu de données contient {} échantillons\".format((raw_dataset.shape[1]-1)//11))\n",
    "\n",
    "# On doit vérifier que chaque nom de colonne matche bien la règle : \"<ID-échantillon>-<ID-piste>\" avec\n",
    "# <ID-piste> == soit ELP, G, A, M, K ou L, G-y, A-y, M-y, K-y, L-y\n",
    "\n",
    "# on définit le pattern regex auquel doivent obénir tous les noms de colonnes des pistes échantillons\n",
    "column_regex_pattern = \"^([0-9a-zA-Z]+)-(ELP|G|A|M|K|L)(-y)?$\"\n",
    "\n",
    "# puis on le checke pour chaque nom de colonne\n",
    "sample_columns = raw_dataset.columns[1:].tolist()\n",
    "for c,sample_column in enumerate(sample_columns): # pour chaque nom de colonne\n",
    "    if re.match(column_regex_pattern, sample_column) is None: # check regex\n",
    "        print(COLOR_PRINT_RED_START + \"Colonne à l'index {} : nom de colonne incorrect : <{}>\".format(c,sample_column) + COLOR_PRINT_RED_END)\n",
    "        \n",
    "        # Enfin, on va vérifier le nombre d'échantillons en fonction des noms de colonnes\n",
    "\n",
    "samples_list = {}\n",
    "for c,sample_column in enumerate(sample_columns): # pour chaque nom de colonne\n",
    "    # on extrait le numéro de l'échantillon du nom de colonne :\n",
    "    sample_ID = re.sub(column_regex_pattern, \"\\\\1\", sample_column)\n",
    "    \n",
    "    # et l'identifiant de la piste (ELP, G, A, M, K, L, G-y, A-y, M-y, K-y, L-y)\n",
    "    track_ID = re.sub(column_regex_pattern, \"\\\\2\", sample_column) + re.sub(column_regex_pattern, \"\\\\3\", sample_column)\n",
    "    \n",
    "    # on stocke le tout dans un dict\n",
    "    if sample_ID not in samples_list.keys(): # c'est la première colonne que l'on trouve pour cet échantillon\n",
    "        samples_list[sample_ID] = {\"ELP\":0,\"G\":0,\"A\":0,\"M\":0,\"K\":0,\"L\":0,\"G-y\":0,\"A-y\":0,\"M-y\":0,\"K-y\":0,\"L-y\":0}\n",
    "        \n",
    "    # on vérifie que l'indice de piste soit bien repértorié (ELP, G, A, M, K, L, G-y, A-y, M-y, K-y, L-y)\n",
    "    if track_ID not in samples_list[sample_ID].keys():\n",
    "        print(COLOR_PRINT_RED_START + \"Type de piste inconnu pour l'échantillon <{}> : <{}>\".format(sample_ID,track_ID) + COLOR_PRINT_RED_END)\n",
    "        \n",
    "    # on ajoute donc le compteur pour la piste retrouvée ici\n",
    "    samples_list[sample_ID][track_ID] += 1\n",
    "    \n",
    "# On peut donc vérifier dans notre dict compilé la cohérence des données :\n",
    "\n",
    "for sample_ID,sample_data in samples_list.items():\n",
    "    if sample_data != {'ELP': 1, 'G': 1, 'A': 1, 'M': 1, 'K': 1, 'L': 1, 'G-y': 1, 'A-y': 1, 'M-y': 1, 'K-y': 1, 'L-y': 1}:\n",
    "        print(COLOR_PRINT_RED_START + \"Erreur dans les colonnes retrouvées pour l'échantillon <{}> : {}\".format(sample_ID,sample_data) + COLOR_PRINT_RED_END)\n",
    "        \n",
    "print(\"Ended columns QC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-effectiveness",
   "metadata": {},
   "source": [
    "### 2.3. Quality check des données échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authentic-planning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start samples QC\n",
      "Ended samples QC\n"
     ]
    }
   ],
   "source": [
    "print(\"Start samples QC\")\n",
    "\n",
    "possible_labels = (\"IgG_L\", \"IgG_K\", \"IgA_L\", \"IgA_K\", \"IgM_L\", \"IgM_K\", \"Complex\", \"Normal\", )\n",
    "\n",
    "# pour chaque échantillon :\n",
    "for sample_ID,sample_data in samples_list.items():\n",
    "\n",
    "    # on récupère la label de l'échantillon et on vérifie qu'elle est conforme aux labels attendues (listées ci-dessus)\n",
    "    sample_label = raw_dataset.loc[:,sample_ID+\"-ELP\"].iloc[0]\n",
    "    if sample_label not in possible_labels:\n",
    "        print(COLOR_PRINT_RED_START + \"Erreur dans la label pour l'échantillon <{}> : <{}> (doit être une parmi : {})\".format(sample_ID,sample_label,possible_labels) + COLOR_PRINT_RED_END)\n",
    "\n",
    "    # on checke que la 1e ligne de G, A, M, K, L est bien vide\n",
    "    for track in (\"G\",\"A\",\"M\",\"K\",\"L\"):\n",
    "        if pd.isna(raw_dataset.loc[:,sample_ID+\"-\"+track].iloc[0]) == False:\n",
    "            print(COLOR_PRINT_RED_START + \"La première valeur de la colonne {} pour l'échantillon <{}> n'est pas vide\".format(track,sample_ID) + COLOR_PRINT_RED_END)\n",
    "\n",
    "    # on checke que les données de chaque courbe sont bien au format numérique ENTIER\n",
    "    for track in (\"ELP\",\"G\",\"A\",\"M\",\"K\",\"L\"):\n",
    "        if all(raw_dataset.loc[:,sample_ID+\"-\"+track].iloc[1:].astype(str).str.match(\"^[0-9]+$\")) == False:\n",
    "            print(COLOR_PRINT_RED_START + \"Au moins une valeur de la colonne {} pour l'échantillon <{}> n'est pas au format numérique ENTIER\".format(track,sample_ID) + COLOR_PRINT_RED_END)\n",
    "\n",
    "print(\"Ended samples QC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-tuition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
